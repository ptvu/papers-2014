{
 "metadata": {
  "name": "",
  "signature": "sha256:7e9fd5b99a2682dce87860263208575fd241d4caf10c8f13e78b9c27a6792f6a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from anser_indicus.config_settings import DATA_PATH, STAIRCASE_JSON_PATH, QUERY_PATH\n",
      "from anser_indicus.data.database_pool import DatabasePool\n",
      "from anser_indicus.data.queryable_database import QueryableDatabase, KeywordSelection, TimeSelection, Selection, AllSelection\n",
      "from anser_indicus.preprocessing.sparse_matrix import SparseMatrix\n",
      "from anser_indicus.utilities.utc import flexible_htm, htm, mth\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.linear_model import Lasso, SGDClassifier, LogisticRegression, SGDRegressor\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "\n",
      "def to_unix_timestamp(year):\n",
      "    return flexible_htm(str(year) + \"-01-01\")\n",
      "def to_year(unix_time_stamp):\n",
      "    return int(mth(unix_time_stamp, \"%Y\"))\n",
      "def get_time_slices(database_name):\n",
      "    db = QueryableDatabase(database_name)\n",
      "    min_year, max_year = (to_year(x) for x in db.time_range())\n",
      "    time_slices = [(to_unix_timestamp(x), to_unix_timestamp(x+1)-1) for x in range(min_year, max_year)]\n",
      "    return time_slices"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "database_name = 'nips_1987_2013'\n",
      "query = 'optimization'\n",
      "keywords = [query]\n",
      "time_range = (1262304000, 1293839999)\n",
      "print keywords, time_range\n",
      "\n",
      "db_pool = DatabasePool()\n",
      "db = QueryableDatabase(database_name, pool=db_pool)\n",
      "or_selection, not_selection = Selection(), Selection()\n",
      "not_selection += TimeSelection(time_range)\n",
      "or_selection += KeywordSelection(keywords)\n",
      "or_selection &= TimeSelection(time_range)\n",
      "db.select(not_selection, classlabel=0, dontclear=False)\n",
      "db.select(or_selection, classlabel=1, dontclear=True)\n",
      "matrix_data = SparseMatrix()\n",
      "matrix_data.attach_database(database_name, pool=db_pool)\n",
      "matrix_data.load_from_iterator(db.iterate_selection())\n",
      "classification_vector = matrix_data.load_classification_vector(db.iterate_selection_classes())\n",
      "print matrix_data.mat.shape, classification_vector.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['optimization'] (1262304000, 1293839999)\n",
        "attaching database nips_1987_2013\n",
        "(292, 29115)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " (292, 1)\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "def SGD_regression(matrix, class_vector):\n",
      "    transformer = TfidfTransformer(norm='l2')\n",
      "    A = transformer.fit_transform(matrix.mat)\n",
      "    b = np.ravel(class_vector)\n",
      "    ml = SGDRegressor(loss='squared_loss', penalty='l1', alpha = 0.00001, l1_ratio = 0.9,  n_iter = 10)\n",
      "    ml.fit(A, b)\n",
      "    return ml.coef_\n",
      "\n",
      "def perform_classification(matrix, class_vector):\n",
      "    return SGD_regression(matrix, class_vector)\n",
      "\n",
      "class Keyword:\n",
      "    def __init__(self, termid, term, weight, time):\n",
      "        self.termid = termid\n",
      "        self.term = term\n",
      "        self.weight = weight\n",
      "        self.weights_per_time = {to_year(time) : weight}\n",
      "        self.time_occ = [to_year(time)]\n",
      "        self.min_time_occ = to_year(time)\n",
      "        self.n_occurrences = 1\n",
      "\n",
      "    def __iadd__(self, other):\n",
      "        self.weight += other.weight\n",
      "        self.time_occ += other.time_occ\n",
      "        self.min_time_occ = min(self.min_time_occ, other.min_time_occ)\n",
      "        self.weights_per_time.update(other.weights_per_time)\n",
      "        self.n_occurrences += other.n_occurrences\n",
      "        return self\n",
      "\n",
      "    def __eq__(self, other):\n",
      "        return self.termid == other.termid\n",
      "\n",
      "    def __cmp__(self, other):\n",
      "        return cmp(self.weight, other.weight)\n",
      "\n",
      "    def __repr__(self):\n",
      "        return self.term + \" \" + str(self.weight)\n",
      "    \n",
      "query_terms = [query]\n",
      "matrix = matrix_data\n",
      "class_vector = classification_vector\n",
      "weights = perform_classification(matrix_data, classification_vector)\n",
      "column_ids = [matrix.lexicon[x] for x in matrix.get_term_list()]\n",
      "terms = matrix.lookup_terms(column_ids)\n",
      "term_ids = [x[1] for x in matrix.get_term_list()]\n",
      "corresponding_weights = [weights[x] for x in column_ids]\n",
      "\n",
      "# Take max of weights for normalization\n",
      "max_weight = max(weights)\n",
      "max_weight = 1 if max_weight < 1E-9 else max_weight\n",
      "\n",
      "# Add term as Keywords to the set, filtering out bad terms\n",
      "keywords = []\n",
      "for term, term_id, weight in zip(terms, term_ids, corresponding_weights):\n",
      "    if weight/max_weight >= 1E-9 and term not in query_terms and len(term) > 1 and term.isalpha():\n",
      "        keywords.append(Keyword(term_id, term, 100.0*weight/max_weight, time_slice[0]))\n",
      "num_documents_with_terms = sum([1 if x == 1 else 0 for x in class_vector])\n",
      "percentage_with_query = num_documents_with_terms / float(len(class_vector))\n",
      "keywords.sort(reverse=True)\n",
      "N_KEYWORDS_PER_SLICE = 20\n",
      "print([x for x in keywords][:N_KEYWORDS_PER_SLICE])\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[learning 100.0, algorithm 85.9638063256, data 85.9464910283, model 85.5475518728, function 78.7252289189, problem 73.8431359534, set 71.1773463803, matrix 70.1938636473, loss 62.2414994059, policy 60.4806688522, image 55.4417033202, convex 54.1828432877, training 52.6974774213, graph 52.541476349, log 50.0078153196, features 47.7261046607, method 47.0622159876, time 47.0209242495, models 45.8986477968, kernel 45.5213382571]\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "DEBUG"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "classification_vector"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 55,
       "text": [
        "array([[ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.],\n",
        "       [ 0.],\n",
        "       [ 1.]], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    }
   ],
   "metadata": {}
  }
 ]
}