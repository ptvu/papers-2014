{
 "metadata": {
  "name": "",
  "signature": "sha256:643295cfa26fe253ade478fc6705a6addb9bfa997911e36479ca88968eb60f36"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data preprocessing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "from scipy import *\n",
      "from scipy.sparse import *\n",
      "from scipy.sparse.linalg import *\n",
      "\n",
      "vocab = [line.strip() for line in open('vocab.nips.txt', 'rb')]\n",
      "stop_words = [not str.isalpha(word) for word in vocab]\n",
      "\n",
      "skiprows = 3\n",
      "I = []\n",
      "J = []\n",
      "V = []\n",
      "with open('docword.nips.txt') as csvfile:\n",
      "    line_cnt = 0\n",
      "    for line in csvfile:\n",
      "        line_cnt = line_cnt + 1\n",
      "        if (line_cnt % 10000000 == 0):\n",
      "            print line_cnt\n",
      "        if (line_cnt == 1):\n",
      "            num_rows = int(line.strip())\n",
      "        if (line_cnt == 2):\n",
      "            num_cols = int(line.strip())\n",
      "        if (line_cnt > skiprows):\n",
      "            row = line.strip().split(' ')\n",
      "            r, c, v = [int(e) for e in row]\n",
      "            r = r - 1\n",
      "            c = c - 1\n",
      "            if (not stop_words[c]):\n",
      "                I.append(r)\n",
      "                J.append(c)\n",
      "                V.append(v)\n",
      "\n",
      "A = scipy.sparse.coo_matrix((V, (I, J)), dtype='float')\n",
      "rank = 11\n",
      "P, D, QT = svds(A, k = rank)\n",
      "save_D = D\n",
      "epsilon = D[0]\n",
      "P = P[:, 1:rank]\n",
      "D = D[1:rank]\n",
      "QT = QT[1:rank, :]\n",
      "\n",
      "S = scipy.sqrt(D)\n",
      "P = P.dot(diag(S))\n",
      "QT = diag(S).dot(QT)\n",
      "print P.shape, QT.shape, epsilon\n",
      "# print scipy.linalg.norm(A - P.dot(QT), ord=2)\n",
      "import cPickle as pickle\n",
      "pickle.dump( (P, QT, epsilon), open( \"lr.pickle\", \"wb\" ) )\n",
      "# pickle.dump( A, open( \"original.pickle\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1500, 10) (10, 12419) 415.764884226\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load preprocessed data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "[Q, P, z] = pickle.load( open( \"pubmed_lowrank_10.pickle\", \"rb\" ) )\n",
      "P = P.T\n",
      "print z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2384.17203177\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Specify query word"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query = 'leukemia'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = [line.strip() for line in open('vocab.pubmed.txt', 'rb')]\n",
      "feature_query_id = -1\n",
      "for i, each in enumerate(vocab):\n",
      "    if each == query:\n",
      "        feature_query_id = i\n",
      "print 'Query ID:', feature_query_id\n",
      "import numpy\n",
      "label = -numpy.ones([Q.shape[0], 1])\n",
      "skiprows = 3\n",
      "with open('docword.pubmed.txt') as csvfile:\n",
      "    line_cnt = 0\n",
      "    for line in csvfile:\n",
      "        line_cnt = line_cnt + 1\n",
      "        if (line_cnt > skiprows):\n",
      "            row = line.strip().split(' ')\n",
      "            r, c, v = [int(e) for e in row]\n",
      "            r = r - 1\n",
      "            c = c - 1\n",
      "            if (c == feature_query_id and v > 0):\n",
      "                label[r] = 1\n",
      "import numpy\n",
      "print 'Positive documents:', len(numpy.where(label == 1)[0])\n",
      "print 'Negative documents:', len(numpy.where(label == -1)[0])                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query ID: 72767\n",
        "Positive documents:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 67843\n",
        "Negative documents: "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "8132157\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Solve the optimization problem"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lambd = 0.15\n",
      "epsilon = 10\n",
      "\n",
      "K = Q.T.dot(Q)\n",
      "y = label\n",
      "from scipy.linalg import *\n",
      "c = inv(sqrtm(K)).dot(Q.T.dot(y))\n",
      "s = numpy.sqrt(y.T.dot(y) - c.T.dot(c))\n",
      "R = P.dot(sqrtm(K))\n",
      "\n",
      "n = P.shape[0]\n",
      "k = K.shape[0]\n",
      "import cvxopt\n",
      "from cvxpy import *\n",
      "w = Variable(n)\n",
      "objective = Minimize(norm(vstack(c - R.T * w, s), 2) + epsilon * norm(w, 2) + lambd * norm(w, 1))\n",
      "p = Problem(objective)\n",
      "\n",
      "import time\n",
      "start = time.time()\n",
      "p.solve()\n",
      "total_time = time.time() - start\n",
      "print 'Total computing time:', total_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total computing time: 42.9786329269\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = sorted(w.value, reverse=True)\n",
      "order = sorted(range(len(weights)), reverse=True, key=lambda k: w.value[k])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUM_WORDS = 10\n",
      "topic_imaging = [(vocab[order[i]], float(w.value[order[i]])) for i in range(NUM_WORDS)]\n",
      "print '\\n'.join([each[0] for each in topic_imaging])\n",
      "print topic_imaging"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "serum\n",
        "camp\n",
        "prl\n",
        "leydig\n",
        "gastrin\n",
        "stimulatory\n",
        "pkc\n",
        "pth\n",
        "prolactin\n",
        "lak\n",
        "[('serum', 2.136582357469604e-12), ('camp', 1.6182171125296296e-12), ('prl', 1.19103634379455e-12), ('leydig', 8.65557505672546e-13), ('gastrin', 7.955906250713832e-13), ('stimulatory', 7.765808031121938e-13), ('pkc', 7.682403469522605e-13), ('pth', 6.951827823254555e-13), ('prolactin', 6.940079245298218e-13), ('lak', 6.930709588136449e-13)]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}