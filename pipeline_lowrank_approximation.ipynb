{
 "metadata": {
  "name": "",
  "signature": "sha256:99668719320428bacaa713bf67c1371e4c96d6922492c61ed2ecc99c8e522292"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Data preprocessing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy\n",
      "from scipy import *\n",
      "from scipy.sparse import *\n",
      "from scipy.sparse.linalg import *\n",
      "\n",
      "vocab = [line.strip() for line in open('vocab.nips.txt', 'rb')]\n",
      "stop_words = [not str.isalpha(word) for word in vocab]\n",
      "\n",
      "skiprows = 3\n",
      "I = []\n",
      "J = []\n",
      "V = []\n",
      "with open('docword.nips.txt') as csvfile:\n",
      "    line_cnt = 0\n",
      "    for line in csvfile:\n",
      "        line_cnt = line_cnt + 1\n",
      "        if (line_cnt % 10000000 == 0):\n",
      "            print line_cnt\n",
      "        if (line_cnt == 1):\n",
      "            num_rows = int(line.strip())\n",
      "        if (line_cnt == 2):\n",
      "            num_cols = int(line.strip())\n",
      "        if (line_cnt > skiprows):\n",
      "            row = line.strip().split(' ')\n",
      "            r, c, v = [int(e) for e in row]\n",
      "            r = r - 1\n",
      "            c = c - 1\n",
      "            if (not stop_words[c]):\n",
      "                I.append(r)\n",
      "                J.append(c)\n",
      "                V.append(v)\n",
      "\n",
      "A = scipy.sparse.coo_matrix((V, (I, J)), dtype='float')\n",
      "rank = 11\n",
      "P, D, QT = svds(A, k = rank)\n",
      "save_D = D\n",
      "epsilon = D[0]\n",
      "P = P[:, 1:rank]\n",
      "D = D[1:rank]\n",
      "QT = QT[1:rank, :]\n",
      "\n",
      "S = scipy.sqrt(D)\n",
      "P = P.dot(diag(S))\n",
      "QT = diag(S).dot(QT)\n",
      "print P.shape, QT.shape, epsilon\n",
      "# print scipy.linalg.norm(A - P.dot(QT), ord=2)\n",
      "import cPickle as pickle\n",
      "pickle.dump( (P, QT, epsilon), open( \"lr.pickle\", \"wb\" ) )\n",
      "# pickle.dump( A, open( \"original.pickle\", \"wb\" ) )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1500, 10) (10, 12419) 415.764884226\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Load preprocessed data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle as pickle\n",
      "[Q, P, z] = pickle.load( open( \"lr.pickle\", \"rb\" ) )\n",
      "P = P.T\n",
      "print z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "415.764884226\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Specify query word"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "query = 'optimization'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vocab = [line.strip() for line in open('vocab.nips.txt', 'rb')]\n",
      "feature_query_id = -1\n",
      "for i, each in enumerate(vocab):\n",
      "    if each == query:\n",
      "        feature_query_id = i\n",
      "print 'Query ID:', feature_query_id\n",
      "import numpy\n",
      "label = -numpy.ones([Q.shape[0], 1])\n",
      "skiprows = 3\n",
      "with open('docword.nips.txt') as csvfile:\n",
      "    line_cnt = 0\n",
      "    for line in csvfile:\n",
      "        line_cnt = line_cnt + 1\n",
      "        if (line_cnt > skiprows):\n",
      "            row = line.strip().split(' ')\n",
      "            r, c, v = [int(e) for e in row]\n",
      "            r = r - 1\n",
      "            c = c - 1\n",
      "            if (c == feature_query_id and v > 0):\n",
      "                label[r] = 1\n",
      "import numpy\n",
      "print 'Positive documents:', len(numpy.where(label == 1)[0])\n",
      "print 'Negative documents:', len(numpy.where(label == -1)[0])                "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Query ID: 7774\n",
        "Positive documents:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 368\n",
        "Negative documents: 1132\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Solve the optimization problem"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lambd = 0.15\n",
      "epsilon = 10\n",
      "\n",
      "K = Q.T.dot(Q)\n",
      "y = label\n",
      "from scipy.linalg import *\n",
      "c = inv(sqrtm(K)).dot(Q.T.dot(y))\n",
      "s = numpy.sqrt(y.T.dot(y) - c.T.dot(c))\n",
      "R = P.dot(sqrtm(K))\n",
      "\n",
      "n = P.shape[0]\n",
      "k = K.shape[0]\n",
      "import cvxopt\n",
      "from cvxpy import *\n",
      "w = Variable(n)\n",
      "objective = Minimize(norm(vstack(c - R.T * w, s), 2) + epsilon * norm(w, 2) + lambd * norm(w, 1))\n",
      "p = Problem(objective)\n",
      "\n",
      "import time\n",
      "start = time.time()\n",
      "p.solve()\n",
      "total_time = time.time() - start\n",
      "print 'Total computing time:', total_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Total computing time: 3.45730090141\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = sorted(w.value, reverse=True)\n",
      "order = sorted(range(len(weights)), reverse=True, key=lambda k: w.value[k])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "NUM_WORDS = 10\n",
      "topic_imaging = [(vocab[order[i]], float(w.value[order[i]])) for i in range(NUM_WORDS)]\n",
      "print '\\n'.join([each[0] for each in topic_imaging])\n",
      "print topic_imaging"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "algorithm\n",
        "neural\n",
        "variables\n",
        "recurrent\n",
        "weight\n",
        "likelihood\n",
        "distribution\n",
        "parameter\n",
        "bound\n",
        "problem\n",
        "[('algorithm', 0.004521082677516274), ('neural', 2.996882576591139e-10), ('variables', 1.3103865198490022e-10), ('recurrent', 1.2513559687316023e-10), ('weight', 1.0735432086025252e-10), ('likelihood', 9.307050725089705e-11), ('distribution', 9.249998574408051e-11), ('parameter', 8.873127491376296e-11), ('bound', 8.799658016290256e-11), ('problem', 7.894390697464088e-11)]\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}