{
 "metadata": {
  "name": "",
  "signature": "sha256:e3c7f2e6c29fc1a23c37497c4abe14168c70242c1c271d0ab3603dd02bf762c6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "POST PROCESSING FROM THE CLASSIFIER"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Now inpect the \"returns\" variable from Dispatcher.py\n",
      "import pickle\n",
      "returns = pickle.load(open('returns.pickle', 'rb'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from collections import Counter, OrderedDict\n",
      "all_words = Counter()\n",
      "for n in range(len(returns)):\n",
      "    (sub_query_npos, sub_words, sub_word_weights, sub_stair_horizontal_line, sub_stair_news) = returns[n]\n",
      "    for word in sub_words.keys():\n",
      "        all_words[word] += 1\n",
      "used_words = set()\n",
      "MAX_USED_WORDS = 30\n",
      "for item in all_words.most_common(MAX_USED_WORDS):\n",
      "    used_words.add(item[0])\n",
      "print(\"USED WORDS::\", used_words)        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('USED WORDS::', set([u'kernel', u'regret', u'energy', u'rank', u'cost', u'dual', u'convex', u'matching', u'clustering', u'matrix', u'gradient', u'graph', u'submodular', u'objective', u'optimal', u'norm', u'function', u'ranking', u'linear', u'max', u'policy', u'loss', u'svm', u'algorithm', u'solution', u'mlp', u'sparse', u'problem', u'margin', u'constraints']))\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "CLASSIFICATION PHASE"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import glob\n",
      "# Year 2010\n",
      "bins = glob.glob(\"/Users/thekid/.ai/databases/nips_1987_2013/y_1262304000_1293839999_content.npz\")\n",
      "from anser_indicus.preprocessing.sparse_matrix import SparseMatrix\n",
      "from anser_indicus.data.database_pool import DatabasePool\n",
      "mat = SparseMatrix()\n",
      "pool = DatabasePool()\n",
      "mat.attach_database('nips_1987_2013',pool=pool)\n",
      "mat.load_from_binary(bins[0],pool=pool)\n",
      "print \"DONE\"\n",
      "ndocs = mat.mat.shape[0]\n",
      "nwords = mat.mat.shape[1]\n",
      "print \"Total # documents = \", ndocs\n",
      "print \"Total # words = \", nwords\n",
      "#############\n",
      "# Compute the binary vector y, each component in {0, 1}\n",
      "#############\n",
      "y = [1 for i in range(int(ndocs))]\n",
      "pos = {'search_by': u'both', 'all': [u'optimization']}\n",
      "print \"pos:\",pos\n",
      "if 'all' in pos:\n",
      "    for term in pos['all']:\n",
      "        print(term)\n",
      "        print(mat.lookup_termids([term]))\n",
      "        col = mat.lookup_termids([term])[0]\n",
      "        if col >= 0 :\n",
      "            print \"query =\", term, \", column =\",col\n",
      "            for i in range(len(y)):\n",
      "                if mat.mat[i, col] == 0:\n",
      "                    y[i] = 0\n",
      "print \"Set up positive class\"\n",
      "\n",
      "npos = sum(y)\n",
      "sub_query_npos = npos * 1.0 / max(1, ndocs)\n",
      "print \"Total # positive documents = \", npos"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "attaching database nips_1987_2013\n",
        "Looking for /Users/thekid/.ai/databases/nips_1987_2013/y_1262304000_1293839999_content.npz\n",
        "split binname: /Users/thekid/.ai/databases/nips_1987_2013/y_1262304000_1293839999_content\n",
        "OPENED\n",
        "LOADED"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CREATED MAT"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "DONE"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total # documents =  292\n",
        "Total # words =  29115\n",
        "pos: {'search_by': u'both', 'all': [u'optimization']}\n",
        "optimization\n",
        "select distinct termid from n1 where term == ?; optimization\n",
        "[533]\n",
        "select distinct termid from n1 where term == ?; optimization\n",
        "query = optimization , column = 533\n",
        "Set up positive class\n",
        "Total # positive documents =  197\n"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = mat.mat\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tfidf_transformer = TfidfTransformer(norm='l2')\n",
      "X_tf = tfidf_transformer.fit_transform(X)\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "ml = SGDClassifier(loss='log', penalty='l2', alpha = 0.001, l1_ratio = 0.9,  n_iter = 10)\n",
      "ml.fit(X_tf, y)\n",
      "v = ml.coef_[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "u = sorted(range(nwords), key = lambda k: v[k], reverse=True)\n",
      "max_v = float(v[u[0]])\n",
      "MAX_WORDS = 20 # set to 50 if the number of time ranges is <= 10\n",
      "i = 0\n",
      "j = 0\n",
      "while i < len(u) and j < MAX_WORDS:\n",
      "    #begin = time()\n",
      "    if v[u[i]]/max_v < 1E-9: #hard-threshold relatively very low scores\n",
      "        i += 1\n",
      "        continue\n",
      "    i += 1\n",
      "    word = mat.lookup_terms([u[i]])[0]\n",
      "    if (len(word) <= 1) or (not word.isalpha()): #if word is a stopword, or word has non-alphabetic letters\n",
      "        continue\n",
      "    \n",
      "    query = 'optimization'\n",
      "    word_is_query_term = (word == query) #ignore predictors that are the query term\n",
      "    if word_is_query_term:\n",
      "        continue\n",
      "    \n",
      "    # now select this word\n",
      "    word_weight = 100.0 * v[u[i]]/max_v\n",
      "    j += 1\n",
      "    print word, word_weight"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "problem 74.8707311812\n",
        "convex 70.3989282554\n",
        "lasso 61.4024390685\n",
        "objective 58.4948309534\n",
        "group 52.7004192008\n",
        "cascade 52.6984018099\n",
        "max 50.1744237423\n",
        "graph 48.8041576532\n",
        "regularization 47.7422403449\n",
        "function 44.2711912557\n",
        "loss 44.0770865679\n",
        "submodular 43.8542902954\n",
        "coding 43.307865391\n",
        "rank 43.0872129245\n",
        "optimal 41.9785715805\n",
        "constraints 41.9280158363\n",
        "image 40.8316264491\n",
        "sparse 40.6805560753\n",
        "norm 40.3747446463\n",
        "solution 39.176577251\n"
       ]
      }
     ],
     "prompt_number": 68
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Output from Statnews Dispatcher\n",
      "('SUB WORDS', {u'function': [(1262304000, 1293839999, 44.271191255713632)], u'loss': [(1262304000, 1293839999, 44.077086567850017)], u'regularization': [(1262304000, 1293839999, 47.742240344940434)], u'group': [(1262304000, 1293839999, 52.700419200806557)], u'max': [(1262304000, 1293839999, 50.174423742252131)], u'image': [(1262304000, 1293839999, 40.831626449074925)], u'coding': [(1262304000, 1293839999, 43.307865390951449)], u'solution': [(1262304000, 1293839999, 39.176577251046872)], u'rank': [(1262304000, 1293839999, 43.087212924498139)], u'cascade': [(1262304000, 1293839999, 52.698401809862325)], u'submodular': [(1262304000, 1293839999, 43.854290295383002)], u'graph': [(1262304000, 1293839999, 48.804157653174194)], u'sparse': [(1262304000, 1293839999, 40.680556075302349)], u'convex': [(1262304000, 1293839999, 70.398928255420969)], u'objective': [(1262304000, 1293839999, 58.494830953444733)], u'optimal': [(1262304000, 1293839999, 41.978571580489259)], u'problem': [(1262304000, 1293839999, 74.870731181181512)], u'constraints': [(1262304000, 1293839999, 41.928015836297305)], u'norm': [(1262304000, 1293839999, 40.374744646258918)], u'lasso': [(1262304000, 1293839999, 61.4024390685451)]})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "('SUB WORDS',\n",
        " {u'cascade': [(1262304000, 1293839999, 52.698401809862325)],\n",
        "  u'coding': [(1262304000, 1293839999, 43.30786539095145)],\n",
        "  u'constraints': [(1262304000, 1293839999, 41.928015836297305)],\n",
        "  u'convex': [(1262304000, 1293839999, 70.39892825542097)],\n",
        "  u'function': [(1262304000, 1293839999, 44.27119125571363)],\n",
        "  u'graph': [(1262304000, 1293839999, 48.804157653174194)],\n",
        "  u'group': [(1262304000, 1293839999, 52.70041920080656)],\n",
        "  u'image': [(1262304000, 1293839999, 40.831626449074925)],\n",
        "  u'lasso': [(1262304000, 1293839999, 61.4024390685451)],\n",
        "  u'loss': [(1262304000, 1293839999, 44.07708656785002)],\n",
        "  u'max': [(1262304000, 1293839999, 50.17442374225213)],\n",
        "  u'norm': [(1262304000, 1293839999, 40.37474464625892)],\n",
        "  u'objective': [(1262304000, 1293839999, 58.49483095344473)],\n",
        "  u'optimal': [(1262304000, 1293839999, 41.97857158048926)],\n",
        "  u'problem': [(1262304000, 1293839999, 74.87073118118151)],\n",
        "  u'rank': [(1262304000, 1293839999, 43.08721292449814)],\n",
        "  u'regularization': [(1262304000, 1293839999, 47.742240344940434)],\n",
        "  u'solution': [(1262304000, 1293839999, 39.17657725104687)],\n",
        "  u'sparse': [(1262304000, 1293839999, 40.68055607530235)],\n",
        "  u'submodular': [(1262304000, 1293839999, 43.854290295383)]})"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "QUERY: OPTIMIZATION - current output from Statnews Dispatcher"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Current statnews dispatcher:\n",
      "from IPython.core.display import HTML\n",
      "HTML('<iframe src=http://statnews.eecs.berkeley.edu/queries/10_1411754434 width = 900 height = 700>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<iframe src=http://statnews.eecs.berkeley.edu/queries/10_1411754434 width = 900 height = 700>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 73,
       "text": [
        "<IPython.core.display.HTML at 0x12285f510>"
       ]
      }
     ],
     "prompt_number": 73
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}